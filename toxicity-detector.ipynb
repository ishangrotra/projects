{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2798066,"sourceType":"datasetVersion","datasetId":1709138}],"dockerImageVersionId":30357,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf \nimport numpy as np \nimport pandas as pd \nimport os ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-11T10:31:47.634382Z","iopub.execute_input":"2023-02-11T10:31:47.635352Z","iopub.status.idle":"2023-02-11T10:31:52.404770Z","shell.execute_reply.started":"2023-02-11T10:31:47.635243Z","shell.execute_reply":"2023-02-11T10:31:52.402197Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:52.410150Z","iopub.execute_input":"2023-02-11T10:31:52.410641Z","iopub.status.idle":"2023-02-11T10:31:54.304645Z","shell.execute_reply.started":"2023-02-11T10:31:52.410605Z","shell.execute_reply":"2023-02-11T10:31:54.303623Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.drop(['id'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.306300Z","iopub.execute_input":"2023-02-11T10:31:54.306743Z","iopub.status.idle":"2023-02-11T10:31:54.331817Z","shell.execute_reply.started":"2023-02-11T10:31:54.306701Z","shell.execute_reply":"2023-02-11T10:31:54.330877Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df[df['toxic']==1]","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.334529Z","iopub.execute_input":"2023-02-11T10:31:54.334925Z","iopub.status.idle":"2023-02-11T10:31:54.364436Z","shell.execute_reply.started":"2023-02-11T10:31:54.334887Z","shell.execute_reply":"2023-02-11T10:31:54.362638Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                             comment_text  toxic  \\\n6            COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n12      Hey... what is it..\\n@ | talk .\\nWhat is it......      1   \n16      Bye! \\n\\nDon't look, come or think of comming ...      1   \n42      You are gay or antisemmitian? \\n\\nArchangel WH...      1   \n43               FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!      1   \n...                                                   ...    ...   \n159494  \"\\n\\n our previous conversation \\n\\nyou fuckin...      1   \n159514                  YOU ARE A MISCHIEVIOUS PUBIC HAIR      1   \n159541  Your absurd edits \\n\\nYour absurd edits on gre...      1   \n159546  \"\\n\\nHey listen don't you ever!!!! Delete my e...      1   \n159554  and i'm going to keep posting the stuff u dele...      1   \n\n        severe_toxic  obscene  threat  insult  identity_hate  \n6                  1        1       0       1              0  \n12                 0        0       0       0              0  \n16                 0        0       0       0              0  \n42                 0        1       0       1              1  \n43                 0        1       0       1              0  \n...              ...      ...     ...     ...            ...  \n159494             0        1       0       1              1  \n159514             0        0       0       1              0  \n159541             0        1       0       1              0  \n159546             0        0       0       1              0  \n159554             0        1       0       1              0  \n\n[15294 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159494</th>\n      <td>\"\\n\\n our previous conversation \\n\\nyou fuckin...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>159514</th>\n      <td>YOU ARE A MISCHIEVIOUS PUBIC HAIR</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159541</th>\n      <td>Your absurd edits \\n\\nYour absurd edits on gre...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159546</th>\n      <td>\"\\n\\nHey listen don't you ever!!!! Delete my e...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159554</th>\n      <td>and i'm going to keep posting the stuff u dele...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>15294 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.head(7)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.365957Z","iopub.execute_input":"2023-02-11T10:31:54.366625Z","iopub.status.idle":"2023-02-11T10:31:54.383293Z","shell.execute_reply.started":"2023-02-11T10:31:54.366583Z","shell.execute_reply":"2023-02-11T10:31:54.382200Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                        comment_text  toxic  severe_toxic  \\\n0  Explanation\\nWhy the edits made under my usern...      0             0   \n1  D'aww! He matches this background colour I'm s...      0             0   \n2  Hey man, I'm really not trying to edit war. It...      0             0   \n3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n4  You, sir, are my hero. Any chance you remember...      0             0   \n5  \"\\n\\nCongratulations from me as well, use the ...      0             0   \n6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1             1   \n\n   obscene  threat  insult  identity_hate  \n0        0       0       0              0  \n1        0       0       0              0  \n2        0       0       0              0  \n3        0       0       0              0  \n4        0       0       0              0  \n5        0       0       0              0  \n6        1       0       1              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.iloc[6]['comment_text']","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.384963Z","iopub.execute_input":"2023-02-11T10:31:54.390495Z","iopub.status.idle":"2023-02-11T10:31:54.401642Z","shell.execute_reply.started":"2023-02-11T10:31:54.390448Z","shell.execute_reply":"2023-02-11T10:31:54.400377Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK'"},"metadata":{}}]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.404978Z","iopub.execute_input":"2023-02-11T10:31:54.407108Z","iopub.status.idle":"2023-02-11T10:31:54.428248Z","shell.execute_reply.started":"2023-02-11T10:31:54.407056Z","shell.execute_reply":"2023-02-11T10:31:54.427266Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                             comment_text  toxic  \\\n159566  \":::::And for the second time of asking, when ...      0   \n159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n159569  And it looks like it was actually you who put ...      0   \n159570  \"\\nAnd ... I really don't think you understand...      0   \n\n        severe_toxic  obscene  threat  insult  identity_hate  \n159566             0        0       0       0              0  \n159567             0        0       0       0              0  \n159568             0        0       0       0              0  \n159569             0        0       0       0              0  \n159570             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>159566</th>\n      <td>\":::::And for the second time of asking, when ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159567</th>\n      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159568</th>\n      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159569</th>\n      <td>And it looks like it was actually you who put ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159570</th>\n      <td>\"\\nAnd ... I really don't think you understand...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.unique(df['comment_text'])\n#reutrns a list of unique objects ","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.432564Z","iopub.execute_input":"2023-02-11T10:31:54.433477Z","iopub.status.idle":"2023-02-11T10:31:54.653015Z","shell.execute_reply.started":"2023-02-11T10:31:54.433433Z","shell.execute_reply":"2023-02-11T10:31:54.651934Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n       ...,\n       'Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.',\n       'And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.',\n       '\"\\nAnd ... I really don\\'t think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":" len(pd.unique(df['comment_text']))\n# len(df['comment_text']) aese karke bhi dekh skta tha  \n ","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.654617Z","iopub.execute_input":"2023-02-11T10:31:54.655102Z","iopub.status.idle":"2023-02-11T10:31:54.844780Z","shell.execute_reply.started":"2023-02-11T10:31:54.655064Z","shell.execute_reply":"2023-02-11T10:31:54.843835Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"159571"},"metadata":{}}]},{"cell_type":"code","source":"#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n#the diff b/w tokenizer and \n#ye text vectorization se haar word ko specific id milegi like i ko 42 mila \n#fir him ko 2 mila aese words ki ek indexed dictionary banegi \n#so now time to slit data into data and labels \nx=df['comment_text']\nx","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.848985Z","iopub.execute_input":"2023-02-11T10:31:54.849331Z","iopub.status.idle":"2023-02-11T10:31:54.857967Z","shell.execute_reply.started":"2023-02-11T10:31:54.849299Z","shell.execute_reply":"2023-02-11T10:31:54.856889Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0         Explanation\\nWhy the edits made under my usern...\n1         D'aww! He matches this background colour I'm s...\n2         Hey man, I'm really not trying to edit war. It...\n3         \"\\nMore\\nI can't make any real suggestions on ...\n4         You, sir, are my hero. Any chance you remember...\n                                ...                        \n159566    \":::::And for the second time of asking, when ...\n159567    You should be ashamed of yourself \\n\\nThat is ...\n159568    Spitzer \\n\\nUmm, theres no actual article for ...\n159569    And it looks like it was actually you who put ...\n159570    \"\\nAnd ... I really don't think you understand...\nName: comment_text, Length: 159571, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df.columns[1:]\n# ye aese : lga ne ka mtlb 2 se leke end tak \n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.859839Z","iopub.execute_input":"2023-02-11T10:31:54.860679Z","iopub.status.idle":"2023-02-11T10:31:54.869742Z","shell.execute_reply.started":"2023-02-11T10:31:54.860640Z","shell.execute_reply":"2023-02-11T10:31:54.868106Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n       'identity_hate'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df[df.columns[1:]]\n#now this will give output in data frame form \n#now we need to convert it into numpy array ","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.871316Z","iopub.execute_input":"2023-02-11T10:31:54.871810Z","iopub.status.idle":"2023-02-11T10:31:54.891910Z","shell.execute_reply.started":"2023-02-11T10:31:54.871774Z","shell.execute_reply":"2023-02-11T10:31:54.891027Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        toxic  severe_toxic  obscene  threat  insult  identity_hate\n0           0             0        0       0       0              0\n1           0             0        0       0       0              0\n2           0             0        0       0       0              0\n3           0             0        0       0       0              0\n4           0             0        0       0       0              0\n...       ...           ...      ...     ...     ...            ...\n159566      0             0        0       0       0              0\n159567      0             0        0       0       0              0\n159568      0             0        0       0       0              0\n159569      0             0        0       0       0              0\n159570      0             0        0       0       0              0\n\n[159571 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159566</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159567</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159568</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159569</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159570</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>159571 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df[df.columns[1:]] ye ek data frame hai  \ny=df[df.columns[1:]].values\ny\n# and is ko numpy array me convert karne ke liye we use the function values\n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.893132Z","iopub.execute_input":"2023-02-11T10:31:54.893510Z","iopub.status.idle":"2023-02-11T10:31:54.904468Z","shell.execute_reply.started":"2023-02-11T10:31:54.893465Z","shell.execute_reply":"2023-02-11T10:31:54.903558Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([[0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       ...,\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0]])"},"metadata":{}}]},{"cell_type":"code","source":"x[0].replace('\\n',' ')","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.906120Z","iopub.execute_input":"2023-02-11T10:31:54.906774Z","iopub.status.idle":"2023-02-11T10:31:54.914665Z","shell.execute_reply.started":"2023-02-11T10:31:54.906737Z","shell.execute_reply":"2023-02-11T10:31:54.913640Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\"Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""},"metadata":{}}]},{"cell_type":"code","source":"x= x.apply(lambda t : t.replace('\\n',' '))\nx\n#https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string \n# for replacing a word in the string \n#https://sparkbyexamples.com/pandas/pandas-apply-with-lambda-examples/ for applying lambda function on python \n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:54.916176Z","iopub.execute_input":"2023-02-11T10:31:54.916821Z","iopub.status.idle":"2023-02-11T10:31:55.033958Z","shell.execute_reply.started":"2023-02-11T10:31:54.916759Z","shell.execute_reply":"2023-02-11T10:31:55.032965Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0         Explanation Why the edits made under my userna...\n1         D'aww! He matches this background colour I'm s...\n2         Hey man, I'm really not trying to edit war. It...\n3         \" More I can't make any real suggestions on im...\n4         You, sir, are my hero. Any chance you remember...\n                                ...                        \n159566    \":::::And for the second time of asking, when ...\n159567    You should be ashamed of yourself   That is a ...\n159568    Spitzer   Umm, theres no actual article for pr...\n159569    And it looks like it was actually you who put ...\n159570    \" And ... I really don't think you understand....\nName: comment_text, Length: 159571, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"max_features=200000#number of words in vocab","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:55.035305Z","iopub.execute_input":"2023-02-11T10:31:55.035747Z","iopub.status.idle":"2023-02-11T10:31:55.041421Z","shell.execute_reply.started":"2023-02-11T10:31:55.035709Z","shell.execute_reply":"2023-02-11T10:31:55.040370Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"vectorizer=tf.keras.layers.TextVectorization(\nmax_tokens=max_features,\noutput_sequence_length=1800,# means ki snetence max 1800 words ka ho skta hai \noutput_mode='int'# means ki haar ek word ko ek int value denge not the one hot encodign type \n)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:55.042773Z","iopub.execute_input":"2023-02-11T10:31:55.043388Z","iopub.status.idle":"2023-02-11T10:31:58.579286Z","shell.execute_reply.started":"2023-02-11T10:31:55.043350Z","shell.execute_reply":"2023-02-11T10:31:58.578304Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2023-02-11 10:31:55.943848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:56.029788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:56.030665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:56.033237: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-11 10:31:56.033541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:56.034268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:56.034882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:58.180500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:58.181382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:58.182082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-11 10:31:58.182671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"type(x)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:58.580911Z","iopub.execute_input":"2023-02-11T10:31:58.581595Z","iopub.status.idle":"2023-02-11T10:31:58.594027Z","shell.execute_reply.started":"2023-02-11T10:31:58.581553Z","shell.execute_reply":"2023-02-11T10:31:58.592371Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"pandas.core.series.Series"},"metadata":{}}]},{"cell_type":"code","source":"#now to convert x to numpy array x.values karlena series data ko numpy array me change karne ke liye \ntype(x.values)\nx.values\nx","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:58.596830Z","iopub.execute_input":"2023-02-11T10:31:58.597152Z","iopub.status.idle":"2023-02-11T10:31:58.618620Z","shell.execute_reply.started":"2023-02-11T10:31:58.597123Z","shell.execute_reply":"2023-02-11T10:31:58.617428Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0         Explanation Why the edits made under my userna...\n1         D'aww! He matches this background colour I'm s...\n2         Hey man, I'm really not trying to edit war. It...\n3         \" More I can't make any real suggestions on im...\n4         You, sir, are my hero. Any chance you remember...\n                                ...                        \n159566    \":::::And for the second time of asking, when ...\n159567    You should be ashamed of yourself   That is a ...\n159568    Spitzer   Umm, theres no actual article for pr...\n159569    And it looks like it was actually you who put ...\n159570    \" And ... I really don't think you understand....\nName: comment_text, Length: 159571, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"x.values","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:58.621330Z","iopub.execute_input":"2023-02-11T10:31:58.622027Z","iopub.status.idle":"2023-02-11T10:31:58.630500Z","shell.execute_reply.started":"2023-02-11T10:31:58.621987Z","shell.execute_reply":"2023-02-11T10:31:58.629313Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array([\"Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n       ...,\n       'Spitzer   Umm, theres no actual article for prostitution ring.  - Crunch Captain.',\n       'And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.',\n       '\" And ... I really don\\'t think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"type(x.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:58.631897Z","iopub.execute_input":"2023-02-11T10:31:58.632826Z","iopub.status.idle":"2023-02-11T10:31:58.640015Z","shell.execute_reply.started":"2023-02-11T10:31:58.632786Z","shell.execute_reply":"2023-02-11T10:31:58.638869Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"#abi  i will call adapt \n#During adapt(), the layer will build a vocabulary of all string tokens seen in the dataset,\n# sorted by occurrence count, with ties broken by sort order of the tokens (high to low). \n#At the end of adapt(), if max_tokens is set, the vocabulary wil be truncated to max_tokens size.\nvectorizer.adapt(x.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:31:58.641479Z","iopub.execute_input":"2023-02-11T10:31:58.643129Z","iopub.status.idle":"2023-02-11T10:32:09.208097Z","shell.execute_reply.started":"2023-02-11T10:31:58.643085Z","shell.execute_reply":"2023-02-11T10:32:09.206964Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2023-02-11 10:31:58.795273: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"vectorizer.get_vocabulary()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:09.209451Z","iopub.execute_input":"2023-02-11T10:32:09.209806Z","iopub.status.idle":"2023-02-11T10:32:14.749659Z","shell.execute_reply.started":"2023-02-11T10:32:09.209771Z","shell.execute_reply":"2023-02-11T10:32:14.748515Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"['',\n '[UNK]',\n 'the',\n 'to',\n 'of',\n 'and',\n 'a',\n 'you',\n 'i',\n 'is',\n 'that',\n 'in',\n 'it',\n 'for',\n 'this',\n 'not',\n 'on',\n 'be',\n 'as',\n 'have',\n 'are',\n 'your',\n 'with',\n 'if',\n 'article',\n 'was',\n 'or',\n 'but',\n 'page',\n 'my',\n 'an',\n 'from',\n 'by',\n 'do',\n 'at',\n 'about',\n 'me',\n 'so',\n 'wikipedia',\n 'can',\n 'what',\n 'there',\n 'all',\n 'has',\n 'will',\n 'talk',\n 'please',\n 'would',\n 'its',\n 'no',\n 'one',\n 'just',\n 'like',\n 'they',\n 'he',\n 'dont',\n 'which',\n 'any',\n 'been',\n 'should',\n 'more',\n 'we',\n 'some',\n 'other',\n 'who',\n 'see',\n 'here',\n 'also',\n 'his',\n 'think',\n 'im',\n 'because',\n 'know',\n 'how',\n 'am',\n 'people',\n 'why',\n 'edit',\n 'articles',\n 'only',\n 'out',\n 'up',\n 'when',\n 'were',\n 'use',\n 'then',\n 'may',\n 'time',\n 'did',\n 'them',\n 'now',\n 'being',\n 'their',\n 'than',\n 'thanks',\n 'even',\n 'get',\n 'make',\n 'good',\n 'had',\n 'very',\n 'information',\n 'does',\n 'could',\n 'well',\n 'want',\n 'such',\n 'sources',\n 'way',\n 'name',\n 'these',\n 'deletion',\n 'pages',\n 'first',\n 'help',\n 'new',\n 'editing',\n 'source',\n 'go',\n 'need',\n 'say',\n 'section',\n 'edits',\n 'again',\n 'thank',\n 'where',\n 'user',\n 'made',\n 'many',\n 'much',\n 'really',\n 'used',\n 'most',\n 'discussion',\n 'find',\n 'same',\n 'ive',\n 'deleted',\n 'into',\n 'fuck',\n 'those',\n 'work',\n 'since',\n 'before',\n 'after',\n 'point',\n 'add',\n 'look',\n 'right',\n 'read',\n 'image',\n 'take',\n 'still',\n 'over',\n 'someone',\n 'him',\n 'two',\n 'back',\n 'too',\n 'fact',\n 'link',\n 'said',\n 'own',\n 'something',\n 'going',\n 'youre',\n 'blocked',\n 'list',\n 'stop',\n 'without',\n 'content',\n 'hi',\n 'under',\n 'editors',\n 'our',\n 'block',\n 'thats',\n 'us',\n 'added',\n 'utc',\n 'history',\n 'another',\n 'doesnt',\n 'removed',\n 'might',\n 'note',\n 'however',\n 'sure',\n 'place',\n 'never',\n 'done',\n 'welcome',\n 'her',\n 'case',\n 'put',\n 'personal',\n 'seems',\n 'reason',\n 'better',\n 'using',\n 'yourself',\n 'cant',\n 'actually',\n 'ask',\n 'comment',\n 'while',\n 'vandalism',\n 'feel',\n 'question',\n 'anything',\n 'believe',\n 'person',\n 'links',\n 'things',\n 'both',\n 'didnt',\n 'comments',\n 'best',\n 'ill',\n 'part',\n 'she',\n 'hope',\n 'policy',\n 'against',\n 'off',\n 'keep',\n 'already',\n 'free',\n 'wiki',\n 'thing',\n 'nothing',\n 'change',\n 'wrong',\n 'though',\n 'problem',\n 'remove',\n 'little',\n 'subject',\n 'â€¢',\n 'others',\n 'trying',\n 'tag',\n 'copyright',\n 'must',\n 'understand',\n 'above',\n 'few',\n 'anyone',\n 'speedy',\n 'last',\n 'issue',\n 'give',\n 'questions',\n 'agree',\n 'rather',\n 'years',\n 'let',\n '2',\n 'different',\n 'editor',\n 'long',\n 'reliable',\n 'making',\n 'world',\n 'come',\n 'sorry',\n 'isnt',\n 'reference',\n 'mean',\n 'continue',\n 'try',\n 'references',\n 'found',\n 'doing',\n 'text',\n 'great',\n 'leave',\n 'says',\n 'got',\n 'probably',\n 'english',\n 'original',\n 'every',\n '1',\n 'simply',\n 'word',\n 'users',\n 'fair',\n 'hello',\n 'either',\n 'check',\n 'least',\n 'adding',\n 'ip',\n 'show',\n 'site',\n 'state',\n 'else',\n 'delete',\n 'consensus',\n 'enough',\n 'request',\n 'far',\n 'opinion',\n 'created',\n 'around',\n 'life',\n 'day',\n 'between',\n 'through',\n 'example',\n 'view',\n 'yes',\n 'reverted',\n 'yet',\n 'etc',\n 'id',\n 'matter',\n 'shit',\n 'u',\n 'war',\n 'notable',\n 'contributions',\n 'given',\n 'thought',\n 'material',\n 'book',\n 'admin',\n 'write',\n 'post',\n 'down',\n 'account',\n 'clearly',\n 'having',\n 'encyclopedia',\n 'lot',\n 'support',\n 'real',\n 'bad',\n 'message',\n 'needs',\n 'images',\n 'tell',\n 'seem',\n 'called',\n 'maybe',\n 'evidence',\n 'instead',\n 'ever',\n '3',\n 'correct',\n 'saying',\n 'clear',\n 'always',\n 'number',\n 'important',\n 'further',\n 'quite',\n 'perhaps',\n 'old',\n 'â€”',\n 'true',\n 'until',\n 'hate',\n 'states',\n 'whether',\n 'consider',\n 'written',\n 'claim',\n 'language',\n 'media',\n 'bit',\n 'once',\n 'guidelines',\n 'term',\n 'criteria',\n 'research',\n 'nigger',\n 'version',\n 'times',\n 'website',\n 'getting',\n 'fucking',\n 'theres',\n 'review',\n 'mention',\n 'pov',\n 'oh',\n 'makes',\n 'several',\n 'revert',\n 'considered',\n 'changes',\n 'cannot',\n 'words',\n 'idea',\n 'title',\n 'suck',\n 'address',\n 'notice',\n 'based',\n 'top',\n 'following',\n 'current',\n 'each',\n 'listed',\n 'means',\n 'possible',\n 'group',\n 'facts',\n 'regarding',\n 'care',\n 'rules',\n 'second',\n 'main',\n 'template',\n 'mentioned',\n 'general',\n 'year',\n 'attack',\n 'kind',\n 'whole',\n 'course',\n 'statement',\n 'left',\n 'hey',\n 'date',\n 'include',\n 'seen',\n 'three',\n 'issues',\n 'start',\n 'ass',\n 'ok',\n 'end',\n 'wikipedias',\n 'call',\n 'less',\n 'topic',\n 'gay',\n 'suggest',\n 'man',\n 'including',\n 'happy',\n 'sense',\n 'provide',\n 'create',\n 'big',\n 'days',\n 'myself',\n 'american',\n 'redirect',\n 'known',\n 'sentence',\n 'move',\n 'appropriate',\n 'changed',\n 'love',\n 'notability',\n 'explain',\n 'started',\n 'included',\n 'removing',\n 'project',\n 'anyway',\n 'info',\n 'mind',\n 'school',\n '2005',\n 'next',\n 'looking',\n 'although',\n 'picture',\n 'relevant',\n 'four',\n 'die',\n 'sign',\n 'answer',\n 'style',\n 'away',\n 'per',\n 'order',\n 'warning',\n 'wont',\n 'recent',\n 'youve',\n 'interest',\n 'community',\n 'summary',\n 'later',\n 'lol',\n 'claims',\n 'currently',\n 'discuss',\n 'interested',\n 'policies',\n 'attacks',\n 'especially',\n 'wish',\n 'wrote',\n 'able',\n 'specific',\n 'public',\n 'taken',\n 'writing',\n 'neutral',\n 'full',\n 'names',\n 'within',\n '4',\n 'position',\n 'related',\n 'below',\n 'line',\n 'wanted',\n 'during',\n 'appears',\n 'stuff',\n 'certainly',\n 'official',\n 'nice',\n 'itself',\n 'faith',\n 'everyone',\n 'wasnt',\n 'live',\n 'report',\n 'completely',\n 'according',\n 'unless',\n 'common',\n 'pretty',\n 'country',\n 'everything',\n 'looks',\n 'due',\n 'single',\n 'hes',\n 'process',\n 'contribs',\n 'news',\n 'involved',\n 'god',\n 'fat',\n 'therefore',\n 'obviously',\n 'remember',\n 'lead',\n 'hard',\n 'admins',\n 'came',\n 'edited',\n 'web',\n 'stay',\n 'learn',\n 'response',\n 'future',\n 'past',\n 'asked',\n 'truth',\n 'reading',\n 'power',\n '2006',\n 'stupid',\n 'entry',\n 'quote',\n 'posted',\n 'nor',\n 'talking',\n 'placed',\n '5',\n 'ago',\n 'similar',\n 'email',\n 'game',\n 'published',\n 'exactly',\n 'today',\n 'reasons',\n 'paragraph',\n 'faggot',\n 'city',\n 'argument',\n 'whatever',\n 'system',\n 'working',\n 'false',\n 'sandbox',\n 'moron',\n 'political',\n 'noticed',\n 'useful',\n 'havent',\n 'guy',\n 'high',\n 'regards',\n 'united',\n 'guess',\n 'appreciate',\n 'particular',\n 'deleting',\n 'form',\n 'books',\n 'government',\n 'dispute',\n 'five',\n 'british',\n 'reverting',\n 'major',\n 'problems',\n 'national',\n 'party',\n 'provided',\n 'often',\n 'ones',\n 'become',\n 'lets',\n 'tried',\n 'side',\n 'administrator',\n 'along',\n 'reply',\n 'almost',\n 'needed',\n 'stated',\n 'rule',\n 'took',\n 'search',\n 'knowledge',\n 'banned',\n 'cheers',\n 'taking',\n 'vandalize',\n 'â€“',\n 'certain',\n '2007',\n 'username',\n 'fine',\n 'status',\n 'law',\n 'points',\n 'company',\n 'otherwise',\n 'uploaded',\n 'terms',\n 'explanation',\n 'generally',\n 'sort',\n 'entire',\n 'shows',\n 'description',\n 'whats',\n 'recently',\n 'follow',\n 'guys',\n '2008',\n 'likely',\n 'film',\n 'present',\n 'aware',\n 'saw',\n 'definition',\n 'cited',\n 'alone',\n 'google',\n 'music',\n 'soon',\n 'indeed',\n 'decide',\n 'ban',\n 'wp',\n 'appear',\n 'views',\n 'week',\n 'open',\n 'citation',\n 'contributing',\n 'actual',\n 'set',\n 'interesting',\n 'piece',\n 'c',\n 'short',\n 'white',\n 'told',\n 'theory',\n 'area',\n 'improve',\n 'external',\n 'small',\n 'story',\n 'contact',\n 'simple',\n '2004',\n 'various',\n 'allowed',\n 'moved',\n 'test',\n 'internet',\n 'obvious',\n 'family',\n 'band',\n 'attention',\n 'arent',\n 'proposed',\n 'jew',\n 'themselves',\n 'members',\n 'wouldnt',\n 'result',\n 'disagree',\n 'thus',\n 'cunt',\n 'went',\n 'type',\n 'sites',\n 'ie',\n 'context',\n 'mr',\n 'previous',\n 'nonsense',\n 'actions',\n 'tags',\n 'cite',\n 'works',\n '10',\n 'citations',\n 'jews',\n 'university',\n 're',\n 'enjoy',\n 'conflict',\n 'hours',\n 'shouldnt',\n 'proper',\n 'bias',\n 'category',\n 'job',\n 'longer',\n 'file',\n 'together',\n 'hell',\n 'sourced',\n 'sucks',\n 'addition',\n 'happened',\n 'avoid',\n 'automatically',\n 'author',\n 'valid',\n 'black',\n 'creating',\n 'deal',\n 'worked',\n 'npov',\n 'goes',\n 'himself',\n 'seriously',\n 'john',\n 'death',\n 'proof',\n 'respect',\n 'bitch',\n 'science',\n 'human',\n 'biased',\n 'comes',\n 'helpful',\n 'large',\n 'accepted',\n 'available',\n 'exist',\n 'series',\n 'tildes',\n 'opinions',\n 'hand',\n '6',\n 'indicate',\n 'sections',\n 'rights',\n 'necessary',\n 'act',\n 'meaning',\n 'attempt',\n 'accept',\n 'personally',\n 'statements',\n 'violation',\n 'months',\n 'criticism',\n 'accurate',\n 'action',\n 'usually',\n 'unblock',\n 'german',\n 'pig',\n 'cause',\n 'yeah',\n 'living',\n 'copy',\n 'debate',\n 'upon',\n 'assume',\n 'july',\n 'calling',\n 'standard',\n 'video',\n 'play',\n 'rest',\n 'tagged',\n 'doubt',\n 'sex',\n 'multiple',\n 'theyre',\n 'historical',\n 'serious',\n 'details',\n 'dick',\n 'youll',\n 'separate',\n 'manual',\n 'record',\n 'blocking',\n 'afd',\n 'explaining',\n 'situation',\n 'refer',\n 'wikiproject',\n 'heard',\n 'online',\n 'level',\n 'fix',\n 'asking',\n '7',\n 'complete',\n 'speak',\n 'lack',\n 'messages',\n 'none',\n 'prove',\n 'third',\n 'subjects',\n 'church',\n 'apparently',\n '2009',\n 'south',\n 'rationale',\n 'bullshit',\n 'data',\n 'directly',\n 'august',\n 'period',\n 'legal',\n 'behavior',\n 'difference',\n 'contribute',\n 'greek',\n 'huge',\n 'gets',\n 'wikipedian',\n 'couple',\n 'supposed',\n 'among',\n 'early',\n 'except',\n 'march',\n 'close',\n 'quality',\n 'space',\n 'meant',\n 'countries',\n 'run',\n 'team',\n 'uses',\n 'military',\n 'b',\n 'changing',\n 'existing',\n 'specifically',\n 'significant',\n '2010',\n 'pillars',\n 'fish',\n 'incorrect',\n 'culture',\n 'described',\n 'produce',\n 'jewish',\n '24',\n 'uk',\n 'disruptive',\n 'd',\n 'field',\n 'error',\n 'india',\n 'head',\n 'primary',\n 'friend',\n 'earlier',\n 'sometimes',\n 'outside',\n '20',\n 'purpose',\n 'administrators',\n 'modern',\n 'photo',\n 'table',\n 'particularly',\n 't',\n 'release',\n 'gave',\n 'box',\n 'cases',\n 'inclusion',\n 'born',\n 'pictures',\n 'readers',\n 'june',\n 'character',\n 'vote',\n 'okay',\n 'groups',\n 'anonymous',\n 'abuse',\n 'arguments',\n 'business',\n 'shall',\n 'sock',\n 'tutorial',\n 'january',\n 'friends',\n 'numbers',\n 'control',\n 'thinking',\n 'member',\n 'linked',\n 'happen',\n 'reported',\n 'contest',\n 'coming',\n 'takes',\n 'concerns',\n 'allow',\n 'wait',\n 'majority',\n 'giving',\n '8',\n 'bring',\n 'eg',\n 'worth',\n 'kill',\n 'totally',\n 'red',\n 'force',\n 'decided',\n 'discussed',\n 'house',\n 'finally',\n 'absolutely',\n 'putting',\n 'scientific',\n 'respond',\n 'mistake',\n 'decision',\n 'de',\n 'lost',\n 'entirely',\n '100',\n 'towards',\n 'merely',\n 'home',\n 'neither',\n 'dear',\n 'independent',\n 'international',\n 'song',\n 'balls',\n 'wants',\n 'possibly',\n 'unsigned',\n 'million',\n 'irrelevant',\n 'standards',\n 'april',\n '12',\n 'press',\n 'figure',\n 'organization',\n 'looked',\n 'inappropriate',\n 'chance',\n 'posting',\n 'population',\n 'advice',\n 'posts',\n 'north',\n 'events',\n 'unfortunately',\n 'named',\n 'album',\n ...]"},"metadata":{}}]},{"cell_type":"code","source":"vectorizer('hellow hello dirty fellow')\n# so thie was as we pass a word to vectorizer it converts ","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:14.751456Z","iopub.execute_input":"2023-02-11T10:32:14.751844Z","iopub.status.idle":"2023-02-11T10:32:14.829097Z","shell.execute_reply.started":"2023-02-11T10:32:14.751803Z","shell.execute_reply":"2023-02-11T10:32:14.828123Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(1800,), dtype=int64, numpy=array([88393,   288,  2298, ...,     0,     0,     0])>"},"metadata":{}}]},{"cell_type":"code","source":"#if i wanna se the 1st 4 values \nvectorizer('hellow hello dirty fellow')[:4]\n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:14.830422Z","iopub.execute_input":"2023-02-11T10:32:14.831434Z","iopub.status.idle":"2023-02-11T10:32:14.848591Z","shell.execute_reply.started":"2023-02-11T10:32:14.831393Z","shell.execute_reply":"2023-02-11T10:32:14.847732Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(4,), dtype=int64, numpy=array([88393,   288,  2298,  1741])>"},"metadata":{}}]},{"cell_type":"code","source":"# now we need to make a vectorized data set \nvectorized_text = vectorizer(x)\nvectorized_text\n#159571 ,1800 ki shape isliye hai coz  159571 to  lenght of x hai and 1800 coz we set the max limit to 1800 words\n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:14.850839Z","iopub.execute_input":"2023-02-11T10:32:14.851618Z","iopub.status.idle":"2023-02-11T10:32:19.423848Z","shell.execute_reply.started":"2023-02-11T10:32:14.851589Z","shell.execute_reply":"2023-02-11T10:32:19.422878Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"2023-02-11 10:32:17.830869: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2297822400 exceeds 10% of free system memory.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\narray([[  645,    76,     2, ...,     0,     0,     0],\n       [    1,    54,  2489, ...,     0,     0,     0],\n       [  425,   441,    70, ...,     0,     0,     0],\n       ...,\n       [32445,  7392,   383, ...,     0,     0,     0],\n       [    5,    12,   534, ...,     0,     0,     0],\n       [    5,     8,   130, ...,     0,     0,     0]])>"},"metadata":{}}]},{"cell_type":"code","source":"#bhale hi ma x.values karke paas karu ya x karke pass karu output is eager tensor \ntype(vectorized_text)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:19.425207Z","iopub.execute_input":"2023-02-11T10:32:19.426188Z","iopub.status.idle":"2023-02-11T10:32:19.435675Z","shell.execute_reply.started":"2023-02-11T10:32:19.426148Z","shell.execute_reply":"2023-02-11T10:32:19.432888Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensorflow.python.framework.ops.EagerTensor"},"metadata":{}}]},{"cell_type":"code","source":"# The tf.data.Dataset class .prefetch() function is used to produce a dataset that prefetches the specified elements from this given dataset.\n\n# Syntax:\n# https://www.tensorflow.org/guide/data_performance for cache \ndataset=tf.data.Dataset.from_tensor_slices((vectorized_text,y))\ndataset=dataset.cache()# it will convert the dataset into cache and store it in memory  instead of ram\ndataset=dataset.shuffle(160000) # ye ju bracket ke andar hai ye buffer size hai \n#https://colab.research.google.com/drive/1VS6-dYk3YAzoRmALhgTK7bb2_tBPrB4c?usp=sharing to understand the function of \n# .shuffle and .repeat \n# and how does a batch is formed \n#https://stackoverflow.com/questions/53514495/what-does-batch-repeat-and-shuffle-do-with-tensorflow-datasetb\n# dataset=dataset.repeat() #ye repeat wali cheez ka matlab ni sammajh aaya \n# agar ma buffer data chota kardu to it shows a warning \ndataset=dataset.batch(16)\ndataset=dataset.prefetch(16)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:19.443537Z","iopub.execute_input":"2023-02-11T10:32:19.443835Z","iopub.status.idle":"2023-02-11T10:32:19.462094Z","shell.execute_reply.started":"2023-02-11T10:32:19.443781Z","shell.execute_reply":"2023-02-11T10:32:19.461175Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# now we can see using numpy iterator our batches \ndataset.as_numpy_iterator()","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:19.463614Z","iopub.execute_input":"2023-02-11T10:32:19.464011Z","iopub.status.idle":"2023-02-11T10:32:21.278452Z","shell.execute_reply.started":"2023-02-11T10:32:19.463965Z","shell.execute_reply":"2023-02-11T10:32:21.277510Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"2023-02-11 10:32:19.467024: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2297822400 exceeds 10% of free system memory.\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x7f2ad41e3650>"},"metadata":{}}]},{"cell_type":"code","source":"dataset.as_numpy_iterator().next()\n# ye next function use karne se everytime i refresh it will show the next data set","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:21.279460Z","iopub.execute_input":"2023-02-11T10:32:21.279796Z","iopub.status.idle":"2023-02-11T10:32:23.706373Z","shell.execute_reply.started":"2023-02-11T10:32:21.279761Z","shell.execute_reply":"2023-02-11T10:32:23.705278Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"2023-02-11 10:32:21.283900: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2297822400 exceeds 10% of free system memory.\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(array([[   49,     7,    51, ...,     0,     0,     0],\n        [ 4548,  6810,  2004, ...,     0,     0,     0],\n        [ 3436,    38,  1568, ...,     0,     0,     0],\n        ...,\n        [  462, 46049,   485, ...,     0,     0,     0],\n        [  850,   562,   179, ...,     0,     0,     0],\n        [95517,     4,     2, ...,     0,     0,     0]]),\n array([[0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [1, 0, 1, 0, 1, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0]]))"},"metadata":{}}]},{"cell_type":"code","source":"batch_x ,batch_y=dataset.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:23.710748Z","iopub.execute_input":"2023-02-11T10:32:23.712968Z","iopub.status.idle":"2023-02-11T10:32:25.735587Z","shell.execute_reply.started":"2023-02-11T10:32:23.712928Z","shell.execute_reply":"2023-02-11T10:32:25.734552Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"2023-02-11 10:32:23.718438: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2297822400 exceeds 10% of free system memory.\n","output_type":"stream"}]},{"cell_type":"code","source":" batch_x","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:25.740702Z","iopub.execute_input":"2023-02-11T10:32:25.743067Z","iopub.status.idle":"2023-02-11T10:32:25.754484Z","shell.execute_reply.started":"2023-02-11T10:32:25.743011Z","shell.execute_reply":"2023-02-11T10:32:25.753086Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([[  696,     2,    24, ...,     0,     0,     0],\n       [90752,   189,  3192, ...,     0,     0,     0],\n       [    8,   244,    10, ...,     0,     0,     0],\n       ...,\n       [ 1456,    81,     1, ...,     0,     0,     0],\n       [    8,   130,   201, ...,     0,     0,     0],\n       [ 1312,   454,  2341, ...,     0,     0,     0]])"},"metadata":{}}]},{"cell_type":"code","source":"batch_y\n#this way we can decompse the batch in data and labels \n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:25.758833Z","iopub.execute_input":"2023-02-11T10:32:25.760989Z","iopub.status.idle":"2023-02-11T10:32:25.771284Z","shell.execute_reply.started":"2023-02-11T10:32:25.760950Z","shell.execute_reply":"2023-02-11T10:32:25.770217Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([[0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0]])"},"metadata":{}}]},{"cell_type":"code","source":"# wo repeat function lga ne ki wajah se ye dataset ke lenght infinte bta rha the so dunn use repeat until \n# you know its proper function \n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:25.774784Z","iopub.execute_input":"2023-02-11T10:32:25.777274Z","iopub.status.idle":"2023-02-11T10:32:25.781601Z","shell.execute_reply.started":"2023-02-11T10:32:25.777238Z","shell.execute_reply":"2023-02-11T10:32:25.780571Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# time ro break data in traning testing and validation \ntrain = dataset.take(int(len(dataset)*.7))\n# so what is happening is data set me data is in form of batches so un batches ki lenght li phle \n# fir us ko 0.7 se multiply kia and fir us ko int me convert kia and int me convert hone ke baad\n# jo number aaya utta partition le lia using the take method","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:25.784350Z","iopub.execute_input":"2023-02-11T10:32:25.785362Z","iopub.status.idle":"2023-02-11T10:32:25.797710Z","shell.execute_reply.started":"2023-02-11T10:32:25.785327Z","shell.execute_reply":"2023-02-11T10:32:25.796599Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"val=dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset)*0.2))\n# is me upar ka 0.7 jo use kia tha training data ke liye wo to skip kar dia \n# and jo niiche ka 30 percent tha us me se 20% validation ke liye le liya ","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:25.799647Z","iopub.execute_input":"2023-02-11T10:32:25.800360Z","iopub.status.idle":"2023-02-11T10:32:25.811949Z","shell.execute_reply.started":"2023-02-11T10:32:25.800324Z","shell.execute_reply":"2023-02-11T10:32:25.811105Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"test=dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))\n#just like thee validation data set","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:25.813440Z","iopub.execute_input":"2023-02-11T10:32:25.814034Z","iopub.status.idle":"2023-02-11T10:32:25.831557Z","shell.execute_reply.started":"2023-02-11T10:32:25.814000Z","shell.execute_reply":"2023-02-11T10:32:25.830452Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"len(train)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:25.833730Z","iopub.execute_input":"2023-02-11T10:32:25.835201Z","iopub.status.idle":"2023-02-11T10:32:25.848393Z","shell.execute_reply.started":"2023-02-11T10:32:25.835163Z","shell.execute_reply":"2023-02-11T10:32:25.847347Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"6981"},"metadata":{}}]},{"cell_type":"code","source":"train.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:25.850500Z","iopub.execute_input":"2023-02-11T10:32:25.851251Z","iopub.status.idle":"2023-02-11T10:32:28.343811Z","shell.execute_reply.started":"2023-02-11T10:32:25.851214Z","shell.execute_reply":"2023-02-11T10:32:28.342293Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"2023-02-11 10:32:25.855102: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2297822400 exceeds 10% of free system memory.\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(array([[1540,  179, 1942, ...,    0,    0,    0],\n        [ 148,   90,    8, ...,    0,    0,    0],\n        [  20,   37, 3205, ...,    0,    0,    0],\n        ...,\n        [   2,  413,  310, ...,    0,    0,    0],\n        [   8,  710,   22, ...,    0,    0,    0],\n        [  49,   40,  485, ...,    0,    0,    0]]),\n array([[0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0]]))"},"metadata":{}}]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"#https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work this is how \n#an embedding layer works \nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import LSTM, Dropout,Bidirectional,Dense,Embedding,BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:28.354650Z","iopub.execute_input":"2023-02-11T10:32:28.356862Z","iopub.status.idle":"2023-02-11T10:32:28.372522Z","shell.execute_reply.started":"2023-02-11T10:32:28.356818Z","shell.execute_reply":"2023-02-11T10:32:28.371525Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#the LSTM commonly uses the Sigmoid activation for recurrent connections and the Tanh activation for output.\ninitializer = tf.keras.initializers.HeNormal()\nmodel=Sequential()\nmodel.add(Embedding(max_features,32))\nmodel.add(Bidirectional(LSTM(32,activation='tanh')))\nmodel.add(BatchNormalization())\n# model.add(Bidirectional(LSTM(64,activation='tanh')))\n# model.add(BatchNormalization())\n# for some reason adding 2 bidirecitional lstm layer doesnt seem to work it shows an error \nmodel.add(Dense(128,activation='relu',kernel_initializer=initializer ))\nmodel.add(BatchNormalization())\nmodel.add(Dense(256,activation='relu',kernel_initializer=initializer))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128,activation='relu',kernel_initializer=initializer))\nmodel.add(BatchNormalization())\nmodel.add(Dense(6,activation='sigmoid',kernel_initializer=initializer))\n# ye 6 isliye coz w 6 colums hai toxic and all wale and sigmoid isliye coz \n# sub ka output 0-1 ke beech hai\n#more on embedding layer https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n# ye regularizer ke andar l2(1)  jese 1 likha hai to is ka mtlb haai ki se zyda ni hogi weights ki value\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:28.377076Z","iopub.execute_input":"2023-02-11T10:32:28.379233Z","iopub.status.idle":"2023-02-11T10:32:29.274099Z","shell.execute_reply.started":"2023-02-11T10:32:28.379196Z","shell.execute_reply":"2023-02-11T10:32:29.273173Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:29.275611Z","iopub.execute_input":"2023-02-11T10:32:29.275948Z","iopub.status.idle":"2023-02-11T10:32:29.283712Z","shell.execute_reply.started":"2023-02-11T10:32:29.275911Z","shell.execute_reply":"2023-02-11T10:32:29.282438Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 32)          6400000   \n_________________________________________________________________\nbidirectional (Bidirectional (None, 64)                16640     \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 64)                256       \n_________________________________________________________________\ndense (Dense)                (None, 128)               8320      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 128)               512       \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               33024     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 256)               1024      \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               32896     \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 128)               512       \n_________________________________________________________________\ndense_3 (Dense)              (None, 6)                 774       \n=================================================================\nTotal params: 6,493,958\nTrainable params: 6,492,806\nNon-trainable params: 1,152\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"initial_learning_rate = 0.1\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=10000,\n    decay_rate=0.96,\n    staircase=True)\n\nmodel.compile(\n  optimizer=tf.keras.optimizers.Adadelta(learning_rate=lr_schedule),\n  loss=tf.keras.losses.BinaryCrossentropy(),\n  metrics=['accuracy'])\n# ye staircase= true rakh ne se floow function type kuch apply ho jata hai which converts it into \n#integer  wo ek cosine function use karlia tha a ne wo image cassification project me \n# to fir us me us staircase wali cheez ni thi to model error throw kaar rha tha mera\n# wo kernel regularizer lga te hai loss exploded .-. ya to us ki value i sset to 0.01 to it be goo \n# wrna 1 rakh ne pe to it exploded ","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:29.285556Z","iopub.execute_input":"2023-02-11T10:32:29.286576Z","iopub.status.idle":"2023-02-11T10:32:29.301795Z","shell.execute_reply.started":"2023-02-11T10:32:29.286540Z","shell.execute_reply":"2023-02-11T10:32:29.300754Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# https://www.geeksforgeeks.org/enumerate-in-python/ ye emurate function is used to print \n# which element was  from the data at which iteration when its int loop \nhist=model.fit(train, \n    epochs=5, \n    validation_data=val\n#    callbacks=[early_stopping]\n)\n# in this case we dont need early stopping since we will train for about 10 epochs max","metadata":{"execution":{"iopub.status.busy":"2023-02-11T10:32:29.303782Z","iopub.execute_input":"2023-02-11T10:32:29.304173Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"2023-02-11 10:32:38.760759: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"6981/6981 [==============================] - 794s 113ms/step - loss: 0.1829 - accuracy: 0.6983 - val_loss: 0.1108 - val_accuracy: 0.9196\nEpoch 2/5\n6981/6981 [==============================] - 788s 113ms/step - loss: 0.0944 - accuracy: 0.9442 - val_loss: 0.0916 - val_accuracy: 0.9689\nEpoch 3/5\n6981/6981 [==============================] - 788s 113ms/step - loss: 0.0826 - accuracy: 0.9559 - val_loss: 0.0977 - val_accuracy: 0.9067\nEpoch 4/5\n6981/6981 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9582","output_type":"stream"}]},{"cell_type":"markdown","source":"test\n","metadata":{}},{"cell_type":"code","source":"hist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test=pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv')\n# test.drop(['id'],axis=1,inplace=True)\n# test['comment_text'] =test['comment_text'].apply(lambda t : t.replace('\\n',' '))\n\n# test=test.values\n# test\n# test_labels=pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv')\n# test_labels.drop(['id'],axis=1,inplace=True)\n# test_labels['toxic']=test_labels['toxic'].map({-1:1})\n# test_labels['severe_toxic']=test_labels['severe_toxic'].map({-1:1})\n# test_labels['obscene']=test_labels['obscene'].map({-1:1})\n# test_labels['threat']=test_labels['threat'].map({-1:1})\n# test_labels['insult']=test_labels['insult'].map({-1:1})\n# test_labels['identity_hate']=test_labels['identity_hate'].map({-1:1})\n# test_labels['toxic']=test_labels['toxic'].fillna(0)\n# test_labels['severe_toxic']=test_labels['severe_toxic'].fillna(0)\n# test_labels['obscene']=test_labels['obscene'].fillna(0)\n# test_labels['threat']=test_labels['threat'].fillna(0)\n# test_labels['insult']=test_labels['insult'].fillna(0)\n# test_labels['identity_hate']=test_labels['identity_hate'].fillna(0)\n# test=vectorizer(test)\n# test_labels.values\n# test_dataset=tf.data.Dataset.from_tensor_slices((test,test_labels))\n# test_dataset=test_dataset.cache()\n# test_dataset=test_dataset.shuffle(160000)\n\n\n# test_dataset=test_dataset.batch(16)\n# test_dataset=test_dataset.prefetch(16)\n\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nfig=plt.figure()\nplt.plot(hist.history['loss'],color='teal',label='loss')\nplt.plot(hist.history['val_loss'],color='blue',label='val_loss')\nfig.suptitle('loss',fontsize=28)\nplt.legend(loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision,Recall,CategoricalAccuracy\n# the reason i sued categorical accuracy instead of accuracy is coz \n#  Accuracy is just comparison b/w target values match the predicted values\n# categorical accuracy on the other hand calculates the percentage of predicted values \n# that match with actual values ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre=Precision()\nrec=Recall()\ncat_acc=CategoricalAccuracy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_y.flatten()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in test.as_numpy_iterator():\n    x_test,y_true=batch\n    yhat=model.predict(x_test)\n   \n    \n    pre.update_state(y_true,yhat)\n    rec.update_state(y_true,yhat)\n    cat_acc.update_state(y_true,yhat)\n# ye update state acts updates the values for eveery y_hat,y true","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print( 'the precision is',pre.result().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('the recall is',rec.result().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('the accuracy is',cat_acc.result().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in this case dont flatten it wont work due to the working of how categorical accuracy works \nmodel.save('toxicity.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if we want to reload the model we can use tf.keras.models.load_model('toxicity.h5')\nres=vectorizer(' you are an idiot ')\nt= model.predict(np.expand_dims(res,0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t>0.49","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns[1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['threat']==1]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for batch in test_dataset.as_numpy_iterator():\n#     x_test,y_true=batch\n#     yhat=model.predict(x_test)\n   \n    \n#     pre.update_state(y_true,yhat)\n#     rec.update_state(y_true,yhat)\n#     cat_acc.update_state(y_true,yhat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_dataset\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}